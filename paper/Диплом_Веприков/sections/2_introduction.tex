\section{Введение}

В данной работе решается задача математического моделирования систем с адаптивным управлением \cite{andrievsky2019theory, emelyanov2014mathematical}. Процесс \emph{многократного машинного обучения} описывает ситуацию в системе искусственного интеллекта, когда входные данные для алгоритма обучения могут частично зависеть от предыдущих предсказаний. Объекту исследования ставится в соответствие дискретная динамическая система \cite{galor2007discrete, sandefur1990discrete}, по предельному распределению которой можно понять, присутствует ли в исходной системе скрытая петля положительной обратной связи или происходит усиление ошибки.

Системы машинного обучения и поддержки принятия решений в масштабах общества, по определению, должны оказывать значительное влияние на общество в целом. Недавний анализ \cite{cais2023statementairisk} представляет широкий спектр потенциальных проблем и областей, вызывающих беспокойство, связанных с такими системами \cite{suresh2020misplaced}. Решение этих проблем и  аспекты разработки надежных систем \cite{li2023trustworthy} требуют различных методов проектирования алгоритмов машинного обучения и искусственного интеллекта, сочетающих формальное математическое моделирование, методы инженерии, основанные на данных и долгосрочный анализ рисков \cite{sifakis2023trustworthy, pei2022requirements, he2021challenges}. Одним из ключевых атрибутов качества заслуживающих доверия систем машинного обучения \cite{serban2021practices,toreini2020relationship,siebert2020towards} и социально ответственных алгоритмов ИИ (SRA)\cite{cheng2021socially} является их способность вести себя так, как ожидают пользователи, без каких-либо непредвиденных побочных эффектов.

Методы машинного обучения обычно принимают определенные предположения о данных, например, данные должны быть н.о.р., или стационарными с белым шумом, или среда, в которой работает агент, остается неизменной, или существует дрейф данных, не зависящий от обучающегося алгоритма. Отличительная особенность процесса многократного обучения --- та, которая оправдывает введение названия, --- заключается в том, что состояние среды в процессе становится причинно-следственно зависимым от алгоритма обучения и выдаваемых прогнозов. 
    
При высокой степени автоматизации, то есть при высоком уровне использования предсказаний и жестком следовании им, возникает так называемая \emph{петля положительной обратной связи}. В результате этой петли алгоритм обучения повторно применяется к данным, содержащим предыдущие предсказания. Такое многократное обучение приводит к заметному непреднамеренному сдвигу в распределениях входных данных и предсказаний системы \citep{khritankov2023positive}. Таким образом, подобная система машинного обучения нарушает требования доверия, предъявляемые к социально ответственным алгоритмам искусственного интеллекта. 

Во многих случаях многократный процесс машинного обучения может представлять поведение системы, взаимодействующей со своими пользователями. Например, в системах, рекомендующих потребителям товары или прогнозирующих рыночные цены \cite{khritankov2021existence, sinha2016deconvolving} и обучающихся на основе ответов пользователей, системах поддержки принятия решений в здравоохранении \cite{adam2020hidden} и предиктивных системах охраны порядка и общественной безопасности \cite{ensign2018runaway}, которые вносят смещение в обучающие данные в результате непреднамеренной петли обратной связи.

По итогам работы была подана статья в Q1 журнал \cite{veprikov2024mathematical}, рассказано выступление на конференции ММРО-2023 \cite{veprikov2023matematicheskaya}, материалы которой были поданы в журнал <<Искусственный интеллект и принятие решений>>. Вклад автора диплома состоит в доказательстве теоретических исследований, участии в постановке экспериментов, сборе, обработке и анализе их результатов.

Основным результатом данной работы является модель динамических систем \cite{galor2007discrete} процесса многократного машинного обучения. Формально рассматривается множество $\textbf{F}$ функций плотности вероятности (PDF), каждая из которых описывает данные, доступные системе машинного обучения на заданном временном шаге $t$. Затем вводится отображение $\text{D}_t$, которое действует на заданную функцию плотности $f_t \in \textbf{F}$ для получения нового распределения данных $f_{t+1}$. Общая модель изучаемого нами процесса может быть записана в виде

\begin{equation*} 
        f_{t+1}(x) = \text{D}_t(f_t)(x),\, f_0(x)\, \text{известна}, t \in \{0, 1, 2,...\}.
\end{equation*}

В этой модели отображение $\text{D}_t$ может включать следующие действия, выполняемые системой: семплирование обучающих данных из $f_t(x)$, обновление параметров модели, предоставление одного или нескольких прогнозов пользователям. В результате применения отображения $\text{D}_t$ получается новое распределение с функцией плотности $f_{t+1}(x)$.

%%%% Related work %%%%

Приведем некоторые сведения о исследуемой проблеме. Во многих практических приложениях контекст, в котором используется система машинного обучения, может сам по себе изменять обучающие данные с течением времени. Такой \emph{дрейф данных} может быть вызван какими-то внешними факторами или порожден самой системой. Иллюстрацией этого может быть модель прогнозирования цен на жилье, которая опирается на фактические покупки, рекомендованные моделью \cite{khritankov2021hidden}. Таким образом, модель частично учится на своих собственных прогнозах. Примеры подобных эффектов, таких как эхо-камеры и пузыри-фильтров, широко описаны в литературе \cite{davies2018redefining, spohr2017fake, michiels2022filter, khritankov2021existence}. Энсин и др. \cite{ensign2018runaway} задокументировали эффект положительной петли обратной связи, когда система предиктивного полицейского контроля изменяет данные о происшествиях и вносит смещение в прогнозы. Семинар по проблемам справедливости в машинном обучении \cite{chouldechova2020snapshot} показал, что нерегулируемые скрытые петли обратной связи могут приводить к смещению решений, что делает их нежелательными эффектами.

В качестве еще одной иллюстрации многократного машинного обучения можно привести пример из \cite{taori2023data}. Если в обучающем наборе данных преобладают элементы определенного класса, то любой оптимальный байесовский классификатор будет предсказывать принадлежность новых объектов только к этому преобладающему классу. Это внесет смещение в набор данных. В работе \cite{adam2022error} исследуют, как петли обратной связи в системах машинного обучения влияют на алгоритмы классификации. Авторы описывают эффект \textit{усиления ошибки} в системе искусственного интеллекта в здравоохранении, который приводит к потере качества прогноза с течением времени из-за ошибок, допущенных ранее.

В статье \cite{khritankov2023positive} демонстрируется система машинного обучения, допускающая непреднамеренные петли обратной связи. Авторы доказывают достаточные условия для возникновения этих эффектов, а также предлагают процедуру измерения для оценки данных условий на практике.

В данной работе используется другой подход. Наша постановка задачи использует аппарат дискретных динамических систем \cite{galor2007discrete, sandefur1990discrete}. Этот раздел менее изучен, чем динамические системы с непрерывным временем \cite{katok1995introduction, nemytskii2015qualitative, pauline2022observer, ouannas2017simple}. Основные вопросы исследования дискретных динамических систем включают существование неподвижных точек для данной динамической системы \cite{milnor2018analytic}, поведение предела \cite{sharma2015uniform}, определение того, является ли конкретная траектория регулярной или хаотической \cite{zhang2006discrete}. 

Структура данной дипломной работы следующая. В Разделе~\ref{sec:Problem_statement} формально описывается математическая модель процесса многократного обучения, а вышеупомянутые проблемы доверия рассматриваются как исследовательские вопросы в терминах моделей динамических систем. В Разделе~\ref{sec:mainres} представлены основные теоретические результаты. Для введенной нами динамической системы были найдены достаточные условия для того, чтобы отображение $\text{D}_t$ было преобразованием на $\textbf{F}$, предельное множество и критерий автономности, доказаны условия сходимости, достаточные условия для того, чтобы отображение $\text{D}_t$ было не сжимающим, а также исследовано как преобразование признаков влияет поведение системы. В Разделе~\ref{sec:experiments} проверяются теоретические результаты в серии экспериментов на нескольких наборах данных.